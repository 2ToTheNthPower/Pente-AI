{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4R9pHnRKy8JH"
      },
      "outputs": [],
      "source": [
        "### IMPORTANT:\n",
        "\n",
        "### BECAUSE THIS PROJECT REQUIRES AN ENORMOUS AMOUNT OF TRAINING TIME \n",
        "### (YEARS ON A SINGLE GPU)\n",
        "### THIS CODE WILL NOT STOP RUNNING UNTIL YOU STOP IT, OR IT RUNS OUT OF RAM!\n",
        "\n",
        "### ENABLE GPU ON SYSTEM, IF AVAILABLE, \n",
        "### OR RUNNING JUST ONE TRAINING ITERATION WILL TAKE FOREVER.\n",
        "### THIS PROGRAM USES A *LOT* OF DATA\n",
        "\n",
        "### - Aaron\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJyrXFaczmtg"
      },
      "outputs": [],
      "source": [
        "### library to pickle and compress arrays simultaneously\n",
        "### In it's own cell, so you can be aware that this code \n",
        "### requires this library that you likely don't have yet.\n",
        "!pip install compress_pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-cRFfg1y9Z2",
        "outputId": "e76e3c59-e2e4-4d8f-e65e-00a5d3ee7300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: compress_pickle in /usr/local/lib/python3.8/dist-packages (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.ndimage import correlate\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import networkx as nx\n",
        "from collections.abc import Iterable\n",
        "# import pickle\n",
        "from random import sample\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import compress_pickle as pickle\n",
        "from keras.layers import Dense, Add, Concatenate, Conv2D, Input, MaxPooling2D, Conv2DTranspose, Flatten, Masking, Reshape, LayerNormalization, Softmax, Activation, GaussianNoise\n",
        "from keras import Model\n",
        "# import tensorflow as tf\n",
        "import os\n",
        "import keras\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QSoZEmorxiud"
      },
      "outputs": [],
      "source": [
        "class MultiPente():\n",
        "  def __init__(self, n_players=2, n_games=100, agent=None, graph_path=None):\n",
        "    self.boards = np.zeros(shape=(n_games, 19, 19)).astype(int)\n",
        "    self.prev_boards = np.zeros(shape=(n_games, 19, 19)).astype(int)\n",
        "    self.pairs = np.zeros((n_games, n_players))\n",
        "\n",
        "    self.agent = agent\n",
        "\n",
        "    self.n_players = n_players\n",
        "    self.total_n_games = n_games\n",
        "    self.n_games = n_games\n",
        "    self.completed = np.array([False] * n_games)\n",
        "\n",
        "    self.outcomes = [[],[]]\n",
        "    \n",
        "    if graph_path is None:\n",
        "        self.graph = nx.DiGraph()\n",
        "    else:\n",
        "        try:\n",
        "            with open(graph_path, \"rb\") as f:\n",
        "                self.graph = pickle.load(f)\n",
        "                \n",
        "            print(\"----------------------\")\n",
        "            print(\"LOADED EXISTING GRAPH\")\n",
        "            print(\"----------------------\")\n",
        "            \n",
        "        except:\n",
        "            self.graph = nx.DiGraph()\n",
        "  \n",
        "    self.curr_player = 1\n",
        "\n",
        "    # Create filters for finding surrounded pairs on the board\n",
        "    self.vertical_pairs = np.array([[[1],\n",
        "                                    [-1],\n",
        "                                    [-1],\n",
        "                                    [1]]])\n",
        "\n",
        "    self.horizontal_pairs = np.array([[[1, -1, -1, 1]]])\n",
        "\n",
        "    self.main_diag_pairs = np.array([[[1, 0, 0, 0],\n",
        "                                      [0, -1, 0, 0],\n",
        "                                      [0, 0, -1, 0],\n",
        "                                      [0, 0, 0, 1]]])\n",
        "\n",
        "    self.off_diag_pairs = np.array([[[0, 0, 0, 1],\n",
        "                                    [0, 0, -1, 0],\n",
        "                                    [0, -1, 0, 0],\n",
        "                                    [1, 0, 0, 0]]])\n",
        "    \n",
        "    self.vertical_conv = np.array([[[1],\n",
        "                                    [1],\n",
        "                                    [1],\n",
        "                                    [1],\n",
        "                                    [1]]])\n",
        "\n",
        "    self.horizontal_conv = np.array([[[1, 1, 1, 1, 1]]])\n",
        "\n",
        "    self.main_diag_conv = np.array([[[1, 0, 0, 0, 0],\n",
        "                                      [0, 1, 0, 0, 0],\n",
        "                                      [0, 0, 1, 0, 0],\n",
        "                                      [0, 0, 0, 1, 0],\n",
        "                                      [0, 0, 0, 0, 1]]])\n",
        "    \n",
        "    self.off_diag_conv = np.array([[[0, 0, 0, 0, 1],\n",
        "                                    [0, 0, 0, 1, 0],\n",
        "                                    [0, 0, 1, 0, 0],\n",
        "                                    [0, 1, 0, 0, 0],\n",
        "                                    [1, 0, 0, 0, 0]]])\n",
        "    \n",
        "\n",
        "\n",
        "  def getLegalMoves(self):\n",
        "    mask = (self.boards == 0)\n",
        "    return mask\n",
        "\n",
        "  # def checkRow(self, seq):\n",
        "  #   winning_seq = np.array([1, 1, 1, 1, 1])\n",
        "  #   if 5 in np.convolve(winning_seq, seq, \"valid\"):\n",
        "  #     return True\n",
        "  #   else:\n",
        "  #     return False\n",
        "\n",
        "  def make_hashable(self, a):\n",
        "    out = pickle.dumps(a, compression=\"bz2\")\n",
        "    return out\n",
        "\n",
        "  def getMoveIndices(self, agent=None, train=True, make_random_moves=False):\n",
        "\n",
        "    if make_random_moves:\n",
        "      \n",
        "      self.values = agent.getValues(self.boards, self.pairs, self.last_player, self.graph, train=train, random_agent=True)\n",
        "      \n",
        "      self.mask = self.getLegalMoves()\n",
        "\n",
        "      self.values += np.random.normal(0, .001, size=self.values.shape)\n",
        "\n",
        "      self.values *= self.mask\n",
        "\n",
        "\n",
        "      rng = np.random.default_rng()\n",
        "      seq = np.vstack([rng.permutation(361).reshape(1,19,19) for i in range(self.values.shape[0])])\n",
        "      \n",
        "      self.values *= seq\n",
        "\n",
        "      self.decision_indices = np.swapaxes(np.array((np.argmax(np.max(self.values, axis=2), axis=1), np.argmax(np.max(self.values, axis=1), axis=1))),0,-1)\n",
        "\n",
        "      decisions =(np.amax(self.values, axis=(1,2), keepdims=True) == self.values)\n",
        "\n",
        "      return decisions\n",
        "    \n",
        "    else:\n",
        "      # See http://tim.hibal.org/blog/alpha-zero-how-and-why-it-works/ for more information on UCB scores.\n",
        "\n",
        "      self.values = agent.getValues(self.boards, self.pairs, self.last_player, self.graph, train=train, random_agent=False)\n",
        "      \n",
        "      self.mask = self.getLegalMoves()\n",
        "\n",
        "      # Adding small amount of noise to work around odd issue \n",
        "      # where agent tries to take same move over and over.\n",
        "\n",
        "      self.values += np.random.normal(0, .001, size=self.values.shape)\n",
        "\n",
        "      self.values *= self.mask\n",
        "\n",
        "      rng = np.random.default_rng()\n",
        "      seq = np.vstack([rng.permutation(361).reshape(1,19,19) for i in range(self.values.shape[0])])\n",
        "\n",
        "      self.values *= seq\n",
        "\n",
        "      self.decision_indices = np.swapaxes(np.array((np.argmax(np.max(self.values, axis=2), axis=1), np.argmax(np.max(self.values, axis=1), axis=1))),0,-1)\n",
        "\n",
        "      decisions = (np.amax(self.values, axis=(1,2), keepdims=True) == self.values)\n",
        "\n",
        "      return decisions\n",
        "\n",
        "  def makeMoves(self, player_num, agent, move_num, train=True, make_random_moves=False):\n",
        "\n",
        "    self.last_player = 0 if player_num == 1 else 1\n",
        "\n",
        "    # If in training mode, use UCB scores to choose moves, otherwise choose agent predictions\n",
        "    self.choices = self.getMoveIndices(agent, train=train, make_random_moves=make_random_moves)\n",
        "\n",
        "    # print(np.sum(self.choices, axis=(1,2)))\n",
        "    assert np.all(np.isclose(np.sum(self.choices, axis=(1,2)), 1))\n",
        "\n",
        "    # Cache current game state\n",
        "    self.prev_boards = self.boards\n",
        "\n",
        "    # print(\"MAKING MOVES AND UPDATING BOARD\")\n",
        "\n",
        "    if train:\n",
        "      # Add predecessor nodes to the graph if they aren't already in the graph\n",
        "      self.last_nodes = [self.make_hashable((data[0], data[1], data[2])) for data in list(zip(self.prev_boards.astype(int), self.pairs[:, self.last_player].astype(int), self.pairs[:, player_num].astype(int)))]\n",
        "\n",
        "      # print(\"LAST NODE:\\n\")\n",
        "      # print(list(zip(intermediate_boards.tolist(), self.pairs[:, self.last_player].tolist(), self.pairs[:, player_num].tolist())))\n",
        "\n",
        "      add_last_nodes = [node for node in self.last_nodes if node not in self.graph]\n",
        "      # print(\"NUM ORIGINATING NODES NOT IN GRAPH:\", len(add_last_nodes))\n",
        "      self.graph.add_nodes_from(add_last_nodes, visits=1, outcomes=0.5, player=self.last_player)\n",
        "\n",
        "    # Make moves based on choices\n",
        "    self.boards += self.choices\n",
        "\n",
        "    # All possible cases where a player wins by getting five pieces in a row\n",
        "    case1 = np.sum(correlate(self.boards, self.vertical_conv, mode=\"constant\") >= 4.5, axis=(1,2))\n",
        "    case2 = np.sum(correlate(self.boards, self.horizontal_conv, mode=\"constant\") >= 4.5, axis=(1,2))\n",
        "    case3 = np.sum(correlate(self.boards, self.main_diag_conv, mode=\"constant\") >= 4.5, axis=(1,2))\n",
        "    case4 = np.sum(correlate(self.boards, self.off_diag_conv, mode=\"constant\") >= 4.5, axis=(1,2))\n",
        "\n",
        "    # Nested or statements that calculate if any of these cases are True\n",
        "    finished = np.bitwise_or(np.bitwise_or(np.bitwise_or(case1, case2), case3), case4)\n",
        "    # print(\"NUMBER OF GAMES IN PROGRESS:\", finished.shape)\n",
        "\n",
        "    \n",
        "    # print(vertical_pairs.shape)\n",
        "    # print(horizontal_pairs.shape)\n",
        "    # print(main_diag_pairs.shape)\n",
        "    # print(off_diag_pairs.shape)\n",
        "\n",
        "    # Find pairs that existed on board prior to moving\n",
        "    prev_vert_pairs = (correlate(self.prev_boards, self.vertical_pairs, mode=\"constant\") >= 3.5)\n",
        "    prev_hor_pairs = (correlate(self.prev_boards, self.horizontal_pairs, mode=\"constant\") >= 3.5)\n",
        "    prev_main_pairs = (correlate(self.prev_boards, self.main_diag_pairs, mode=\"constant\") >= 3.5)\n",
        "    prev_off_pairs = (correlate(self.prev_boards, self.off_diag_pairs, mode=\"constant\") >= 3.5)\n",
        "\n",
        "    # Find pairs that exist on board after making moves\n",
        "    curr_vert_pairs = (correlate(self.boards, self.vertical_pairs, mode=\"constant\") >= 3.5)\n",
        "    curr_hor_pairs = (correlate(self.boards, self.horizontal_pairs, mode=\"constant\") >= 3.5)\n",
        "    curr_main_pairs = (correlate(self.boards, self.main_diag_pairs, mode=\"constant\") >= 3.5)\n",
        "    curr_off_pairs = (correlate(self.boards, self.off_diag_pairs, mode=\"constant\") >= 3.5)\n",
        "\n",
        "    # Find ONLY the pairs that resulted directly from making the most recent moves\n",
        "    delta_vert_pairs = np.logical_xor(curr_vert_pairs, prev_vert_pairs)\n",
        "    delta_hor_pairs = np.logical_xor(curr_hor_pairs, prev_hor_pairs)\n",
        "    delta_main_pairs = np.logical_xor(curr_main_pairs, prev_main_pairs)\n",
        "    delta_off_pairs = np.logical_xor(curr_off_pairs, prev_off_pairs)\n",
        "\n",
        "    remove_vert = np.logical_or(delta_vert_pairs, np.roll(delta_vert_pairs, -1, axis=1))\n",
        "    remove_hor = np.logical_or(delta_hor_pairs, np.roll(delta_hor_pairs, -1, axis=2))\n",
        "    remove_main = np.logical_or(delta_main_pairs, np.roll(np.roll(delta_main_pairs, -1, axis=2), -1, axis=1))\n",
        "    remove_off = np.logical_or(np.roll(delta_off_pairs, -1, axis=1), np.roll(delta_off_pairs, -1, axis=2))\n",
        "\n",
        "    # assert np.all(np.sum(remove_vert, axis=(1,2)) % 2 == 0)\n",
        "    # assert np.all(np.sum(remove_hor, axis=(1,2)) % 2 == 0)\n",
        "    # assert np.all(np.sum(remove_main, axis=(1,2)) % 2 == 0)\n",
        "    # assert np.all(np.sum(remove_off, axis=(1,2)) % 2 == 0)\n",
        "\n",
        "    # assert np.all(remove_vert.astype(int) == (-intermediate_boards.astype(int) * remove_vert.astype(int)))\n",
        "    # assert np.all(remove_hor.astype(int) == (-intermediate_boards.astype(int) * remove_hor.astype(int)))\n",
        "    # assert np.all(remove_main.astype(int) == (-intermediate_boards.astype(int) * remove_main.astype(int)))\n",
        "    # assert np.all(remove_off.astype(int) == (-intermediate_boards.astype(int) * remove_off.astype(int)))\n",
        "\n",
        "    remove_all = remove_vert.astype(int) + remove_hor.astype(int) + remove_main.astype(int) + remove_off.astype(int)\n",
        "\n",
        "    # assert not np.any(remove_all < 0) and not np.any(remove_all > 1)\n",
        "    # assert np.all(remove_all == (-intermediate_boards * remove_all).astype(bool))\n",
        "\n",
        "    self.boards -= remove_all\n",
        "    # assert np.all(self.boards >= -.05)\n",
        "\n",
        "    # Update pair count\n",
        "    self.pairs[:, player_num] += np.sum(remove_all, axis=(1,2)) / 2\n",
        "    \n",
        "    # Check if current player won by capturing five or more pairs\n",
        "    self.completed = np.logical_or(finished, (self.pairs[:, player_num] >= 5))\n",
        "\n",
        "    # Flip board to be viewed from perspective of other player\n",
        "    self.boards *= -1\n",
        "\n",
        "    # print(\"ADDING RESULTING NODES TO GRAPH\")\n",
        "\n",
        "    if train:\n",
        "      # Add current nodes to the graph if they aren't already in the graph\n",
        "      curr_nodes = [self.make_hashable((data[0], data[1], data[2])) for data in list(zip(self.boards.astype(int), self.pairs[:, player_num].astype(int), self.pairs[:, self.last_player].astype(int)))]\n",
        "      add_curr_nodes = [node for node in curr_nodes if node not in self.graph]\n",
        "      self.graph.add_nodes_from(add_curr_nodes, visits=1, outcomes=0.5, player=player_num)\n",
        "\n",
        "      # Add edges between previous game states and corresponding new game state\n",
        "      edges_with_data = list(zip(self.last_nodes, curr_nodes, self.decision_indices))\n",
        "\n",
        "      self.graph.add_edges_from([(edge[0], edge[1], {\"move\":edge[2]}) for edge in edges_with_data])\n",
        "\n",
        "      # Store node visit count and outcome (won by player 1 or 0) in graph\n",
        "      completed_nodes_data = list(zip(self.boards[self.completed].astype(int), self.pairs[:, player_num][self.completed].astype(int), self.pairs[:, self.last_player][self.completed].astype(int)))\n",
        "      completed_nodes = [self.make_hashable((data[0], data[1], data[2])) for data in completed_nodes_data]\n",
        "\n",
        "      for node in completed_nodes:\n",
        "        ancestors = nx.ancestors(self.graph, node)\n",
        "        # print(\"NUM ANCESTORS BEING UPDATED:\", len(ancestors))\n",
        "        for node in ancestors:\n",
        "          self.graph.nodes[node][\"visits\"] += 1\n",
        "          self.graph.nodes[node][\"outcomes\"] += int(player_num == self.graph.nodes[node][\"player\"])\n",
        "\n",
        "    # Update outcome records\n",
        "    self.outcomes[player_num] += [move_num]*sum(self.completed)\n",
        "\n",
        "    # Drop all completed games from current computation\n",
        "    self.boards = self.boards[np.logical_not(self.completed)]\n",
        "    self.pairs = self.pairs[np.logical_not(self.completed)]\n",
        "    self.n_games = self.pairs.shape[0]\n",
        "\n",
        "    if self.n_games != self.total_n_games:\n",
        "      self.completed = np.array([False] * self.n_games)\n",
        "    # print(\"SHAPE OF CURRENT BOARDS MATRIX AFTER DROPPING COMPLETED GAMES:\", self.boards.shape)\n",
        "### \n",
        "          \n",
        "    return self.completed  \n",
        "\n",
        "  def getBoards(self):\n",
        "    return self.boards\n",
        "\n",
        "  def play_train(self, agent0, agent1, make_random_moves=[False, False], num_games=100):\n",
        "\n",
        "    self.total_n_games = num_games\n",
        "    self.reset()\n",
        "\n",
        "    count = 0\n",
        "    player = -1\n",
        "    while not np.sum(self.completed) == self.n_games and count < 299:\n",
        "\n",
        "      if player < self.n_players - 1:\n",
        "        player+=1\n",
        "      else:\n",
        "        player=0\n",
        "\n",
        "      if make_random_moves[0]:\n",
        "        if player==0:\n",
        "          fin_list = self.makeMoves(player, agent0, count, make_random_moves=True) \n",
        "      else:\n",
        "        if player==0:\n",
        "          fin_list = self.makeMoves(player, agent0, count)\n",
        "\n",
        "      if make_random_moves[1]:\n",
        "        if player==1:\n",
        "          fin_list = self.makeMoves(player, agent1, count, make_random_moves=True)\n",
        "      else:\n",
        "        if player==1:\n",
        "          fin_list = self.makeMoves(player, agent1, count)\n",
        "\n",
        "      print(\"TAKING TURN\", count)\n",
        "      count += 1\n",
        "\n",
        "    print(\"DONE PLAYING\", self.total_n_games, \"PENTE GAMES\")\n",
        "\n",
        "    # agent0.fit_on_graph(self.graph)\n",
        "\n",
        "    print(\"==================\")\n",
        "    print(\"Player 0 won \", len(self.outcomes[0])/self.total_n_games * 100, \"percent of games\")\n",
        "    print(\"Player 1 won \", len(self.outcomes[1])/self.total_n_games * 100, \"percent of games\")\n",
        "    print(\"==================\")    \n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def play_test(self, agent0, agent1, make_random_moves=[False, False], num_games=100):\n",
        "\n",
        "    self.total_n_games = num_games\n",
        "    self.reset()\n",
        "\n",
        "    count = 0\n",
        "    player = -1\n",
        "    while not np.sum(self.completed) == self.n_games and count < 299:\n",
        "\n",
        "      if player < self.n_players - 1:\n",
        "        player+=1\n",
        "      else:\n",
        "        player=0\n",
        "\n",
        "      # if make_random_moves[0]:\n",
        "      #   if player==0:\n",
        "      #     fin_list = self.makeMoves(player, agent0, count, make_random_moves=True) \n",
        "      # else:\n",
        "      #   if player==0:\n",
        "      #     fin_list = self.makeMoves(player, agent0, count)\n",
        "\n",
        "      # if make_random_moves[1]:\n",
        "      #   if player==1:\n",
        "      #     fin_list = self.makeMoves(player, agent1, count, make_random_moves=True)\n",
        "      # else:\n",
        "      #   if player==1:\n",
        "      #     fin_list = self.makeMoves(player, agent1, count)\n",
        "\n",
        "      print(\"TAKING TURN\", count)\n",
        "      count += 1\n",
        "\n",
        "    print(\"DONE PLAYING\", self.total_n_games, \"PENTE GAMES\")\n",
        "\n",
        "    # agent0.fit_on_graph(self.graph)\n",
        "\n",
        "    print(\"=========TEST GAMES=========\")\n",
        "    print(\"Player 0 won \", len(self.outcomes[0])/self.total_n_games * 100, \"percent of games\")\n",
        "    print(\"Player 1 won \", len(self.outcomes[1])/self.total_n_games * 100, \"percent of games\")\n",
        "    print(\"=========TEST GAMES=========\")    \n",
        "\n",
        "    outcome0, outcome1 = len(self.outcomes[0])/self.total_n_games * 100, len(self.outcomes[1])/self.total_n_games * 100\n",
        "    self.reset()\n",
        "\n",
        "    return outcome0, outcome1\n",
        "\n",
        "  def reset(self):\n",
        "    self.n_games = self.total_n_games\n",
        "    self.boards = np.zeros(shape=(self.n_games, 19, 19))\n",
        "    self.pairs = np.zeros((self.n_games, self.n_players))\n",
        "    self.completed = [False for i in range(self.n_games)]\n",
        "    self.curr_player = 1\n",
        "    self.outcomes = [[],[]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fgUAqlhWzO0h"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "  def __init__(self, agent_path = None):\n",
        "\n",
        "    self.node_values = {}\n",
        "    self.scale_factor = 1\n",
        "\n",
        "    if agent_path is None:\n",
        "      inp1 = Input(shape=(19,19,1))\n",
        "      inp2 = Input(shape=(2,))\n",
        "      # inp_mask = Input(shape=(19,19,1))\n",
        "\n",
        "      noise = GaussianNoise(.1)(inp1)\n",
        "\n",
        "      # Convolve\n",
        "      conv1 = Conv2D(128, 3, activation=\"relu\")(noise)\n",
        "      noise1 = GaussianNoise(.1)(conv1)\n",
        "      conv2 = Conv2D(64, 3, activation=\"relu\")(noise1)\n",
        "      noise2 = GaussianNoise(.1)(conv2)\n",
        "      conv3 = Conv2D(32, 3, activation=\"relu\")(noise2)\n",
        "      noise3 = GaussianNoise(.1)(conv3)\n",
        "      conv4 = Conv2D(16, 3, activation=\"relu\")(noise3)\n",
        "      noise4 = GaussianNoise(.1)(conv4)\n",
        "      conv5 = Conv2D(16, 3, activation=\"relu\")(noise4)\n",
        "\n",
        "      flat1 = Flatten()(conv5)\n",
        "      encoded = Dense(398, activation=\"relu\")(flat1)\n",
        "      emb = keras.layers.Embedding(2, 4)(inp2)\n",
        "      flat_emb = Flatten()(emb)\n",
        "      cat = Concatenate()([encoded, flat_emb])\n",
        "      dense3 = Dense(256, activation=\"relu\")(cat)\n",
        "      dense4 = Dense(400, activation=\"relu\")(dense3)\n",
        "      norm = LayerNormalization()(dense4)\n",
        "      reshape = Reshape(target_shape=(5,5,16))(norm)\n",
        "\n",
        "      # Deconvolve\n",
        "\n",
        "      deconv5 = Conv2DTranspose(16, 3, activation=\"relu\")(reshape)\n",
        "      noise5 = GaussianNoise(.1)(deconv5)\n",
        "      deconv4 = Conv2DTranspose(16, 3, activation=\"relu\")(noise5)\n",
        "      noise6 = GaussianNoise(.1)(deconv4)\n",
        "      deconv3 = Conv2DTranspose(16, 3, activation=\"relu\")(noise6)\n",
        "      noise7 = GaussianNoise(.1)(deconv3)\n",
        "      deconv2 = Conv2DTranspose(32, 3, activation=\"relu\")(noise7)\n",
        "      skip2 = Add()([deconv2, conv3])\n",
        "      deconv1 = Conv2DTranspose(64, 3, activation=\"relu\")(skip2)\n",
        "      noise8 = GaussianNoise(.1)(deconv1)\n",
        "      deconv0 = Conv2DTranspose(8, 3, activation=\"relu\")(noise8)\n",
        "      noise9 = GaussianNoise(.1)(deconv0)\n",
        "      out = Conv2DTranspose(1, 3, activation=\"sigmoid\")(noise9)\n",
        "\n",
        "      policy_head = Masking(mask_value=.5)(out)\n",
        "\n",
        "      # add = Add()([final_deconv * inp_mask, -1*K.cast(inp_mask==0, \"float32\")])\n",
        "\n",
        "      # # mask = Masking(mask_value=-1)(add)\n",
        "\n",
        "      # mask = K.not_equal(add, -1)\n",
        "\n",
        "      # norm13 = LayerNormalization()(final_deconv)\n",
        "      # policy_head = keras.layers.Softmax(name=\"policy_head\")(norm13, mask=mask)\n",
        "\n",
        "      # # Network head for the value of the current (parent) game state\n",
        "      # dense5 = Dense(256, activation=\"relu\")(dense3)\n",
        "      # norm11 = LayerNormalization()(dense5)\n",
        "      # dense6 = Dense(128, activation=\"relu\")(norm11)\n",
        "      # value_head = Dense(1, activation=\"sigmoid\", name=\"value_head\")(dense6)\n",
        "\n",
        "      self.model = Model([inp1, inp2], policy_head)\n",
        "\n",
        "      # Scale up loss to make changes more easily visible during training\n",
        "      self.model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "      # self.model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "      self.model.summary()\n",
        "    else:\n",
        "      self.model = keras.models.load_model(agent_path)\n",
        "\n",
        "    # Hyperparameter for MCTS tuning\n",
        "    self.c = 10\n",
        "\n",
        "  def fit_on_graph(self, graph, num_epochs = 25, batch_size = 256, sample_size = 1000):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      boards = []\n",
        "      pairs = []\n",
        "      masks = []\n",
        "      outcome_train = []\n",
        "      values = []\n",
        "\n",
        "\n",
        "      for data in sample(graph.nodes(data=True), sample_size):\n",
        "        node = data[0]\n",
        "\n",
        "        if node in self.node_values.keys():\n",
        "\n",
        "          outcomes = data[1][\"outcomes\"]\n",
        "          visits = data[1][\"visits\"]\n",
        "          player_num = data[1][\"player\"]\n",
        "          value = outcomes / visits if visits != 0 else .1\n",
        "\n",
        "          (board, cur_pairs, prev_pairs) = pickle.loads(node, compression=\"bz2\")\n",
        "\n",
        "          l = [(edge[0], tuple(edge[2][\"move\"]), self.get_node_value(graph, edge[1]), graph.nodes(data=True)[edge[1]][\"visits\"]) for edge in list(graph.out_edges(node, data=True))]\n",
        "\n",
        "          for data in l:\n",
        "\n",
        "            if data[0] not in self.node_values.keys():\n",
        "\n",
        "              self.node_values[data[0]] = (np.zeros(shape=(19,19)), np.zeros(shape=(19,19)), np.zeros(shape=(19,19)))\n",
        "              \n",
        "              # print(\"DATA[1]\", data[1])\n",
        "\n",
        "\n",
        "            # Add outcome score for child\n",
        "            self.node_values[data[0]][0][data[1]] = data[2]\n",
        "            # Add 1 to indicate that a node has been visited for masking training later\n",
        "            self.node_values[data[0]][1][data[1]] = 1\n",
        "            # Update visit count for particular child node\n",
        "            self.node_values[data[0]][2][data[1]] = data[3]\n",
        "\n",
        "          if np.any(self.node_values[node][2] != 0):\n",
        "\n",
        "            masks.append(self.node_values[node][1])\n",
        "            outcome_train.append(self.scale_factor * self.node_values[node][0])\n",
        "            boards.append(board)\n",
        "            pairs.append([cur_pairs, prev_pairs])\n",
        "            values.append([value])\n",
        "\n",
        "      masks = np.array(masks)\n",
        "      pairs = np.array(pairs)\n",
        "      values = np.array(values)\n",
        "      outcome_train = np.array(outcome_train)\n",
        "      outcome_train = np.reshape(outcome_train, (outcome_train.shape[0], 19, 19, 1))\n",
        "\n",
        "      # Replace all nan values with 0 that resulted by dividing by zero earlier\n",
        "      # print(np.sum(outcome_train[~np.isnan(outcome_train)]))\n",
        "      # t = outcome_train[~np.isnan(outcome_train)].shape[0]*19*19\n",
        "      # print(np.sum(outcome_train[~np.isnan(outcome_train)]) / t)\n",
        "      # sys.exit()\n",
        "      outcome_train[np.isnan(outcome_train)] = 0\n",
        "\n",
        "      boards = np.array(boards)\n",
        "\n",
        "\n",
        "\n",
        "      # Train only on data where \"masks\" has some non-zero elements (i.e. has some explored positions)\n",
        "      temp = (np.sum(masks, axis=(1,2)) != 0)\n",
        "\n",
        "      if np.sum(temp) != 0:\n",
        "          \n",
        "        temp_masks = masks[temp, :, :]\n",
        "        temp_boards = boards[temp, :, :]\n",
        "        temp_outcome = outcome_train[temp, :, :, :]\n",
        "        temp_values = values[temp, :]\n",
        "        temp_pairs = pairs[temp, :]\n",
        "\n",
        "        # Data augmentation with horizontal/vertical flip of boards and transposing\n",
        "\n",
        "        temp_masks = np.vstack((temp_masks, np.flip(temp_masks, axis=1), \n",
        "                                np.transpose(np.flip(temp_masks, axis=1), (0,2,1)), \n",
        "                                np.transpose(temp_masks, (0,2,1)), np.flip(temp_masks, axis=2), \n",
        "                                np.transpose(np.flip(temp_masks, axis=2), (0,2,1)), \n",
        "                                np.transpose(np.flip(np.flip(temp_masks, axis=2), axis=1), (0,2,1)), \n",
        "                                np.flip(np.flip(temp_masks, axis=2), axis=1)))\n",
        "        \n",
        "        temp_boards = np.vstack((temp_boards, np.flip(temp_boards, axis=1), \n",
        "                                np.transpose(np.flip(temp_boards, axis=1), (0,2,1)), \n",
        "                                np.transpose(temp_boards, (0,2,1)), np.flip(temp_boards, axis=2), \n",
        "                                np.transpose(np.flip(temp_boards, axis=2), (0,2,1)), \n",
        "                                np.transpose(np.flip(np.flip(temp_boards, axis=2), axis=1), (0,2,1)), \n",
        "                                np.flip(np.flip(temp_boards, axis=2), axis=1)))\n",
        "        print(temp_outcome.shape)\n",
        "        temp_outcome = np.vstack((temp_outcome, np.flip(temp_outcome, axis=1), \n",
        "                                np.transpose(np.flip(temp_outcome, axis=1), (0,2,1,3)), \n",
        "                                np.transpose(temp_outcome, (0,2,1,3)), np.flip(temp_outcome, axis=2), \n",
        "                                np.transpose(np.flip(temp_outcome, axis=2), (0,2,1,3)), \n",
        "                                np.transpose(np.flip(np.flip(temp_outcome, axis=2), axis=1), (0,2,1,3)), \n",
        "                                np.flip(np.flip(temp_outcome, axis=2), axis=1)))\n",
        "        \n",
        "        temp_values = np.repeat(temp_values, 8, axis=0)\n",
        "        temp_pairs = np.repeat(temp_pairs, 8, axis=0)\n",
        "\n",
        "        temp_boards = np.vstack((temp_boards, -1*temp_boards))\n",
        "        temp_masks = np.repeat(temp_masks, 2, axis=0)\n",
        "        temp_values = np.vstack((temp_values, 1-temp_values))\n",
        "        temp_pairs = np.vstack((temp_pairs, np.flip(temp_pairs, axis=1)))\n",
        "        temp_outcome = np.vstack((temp_outcome, self.scale_factor-temp_outcome))\n",
        "          \n",
        "        self.model.fit([temp_boards, temp_pairs], temp_outcome, epochs=1, batch_size=batch_size, shuffle=True, validation_split=.1)\n",
        "\n",
        "  def get_node_value(self, graph, node):\n",
        "    if graph.nodes(data=True)[node][\"visits\"] != 0:\n",
        "      return graph.nodes(data=True)[node][\"outcomes\"] / graph.nodes(data=True)[node][\"visits\"]\n",
        "    else:\n",
        "      return np.inf\n",
        "\n",
        "  def getValues(self, boards, pairs, player_num, graph, train=True, random_agent=False):\n",
        "\n",
        "    n = boards.shape[0]\n",
        "    # print(board_states.shape)\n",
        "\n",
        "    next_player = 0 if player_num == 1 else 1\n",
        "    players_list = [player_num] * n\n",
        "    curr_pairs = pairs[:, next_player].astype(int)\n",
        "    last_pairs = pairs[:, player_num].astype(int)\n",
        "    inp2 = np.array(list(zip(curr_pairs, last_pairs)))\n",
        "\n",
        "    # # For inference, do not mask out anything, unlike when training where we mask out unexplored moves\n",
        "    # # Masking out illegal moves will be done later\n",
        "    pred_masks = np.ones((n, 19, 19, 1))\n",
        "\n",
        "    if train:\n",
        "      node_list = [multi.make_hashable((x[0], x[1], x[2])) for x in list(zip(boards.astype(int), last_pairs, curr_pairs))]\n",
        "\n",
        "      l = [(edge[0], tuple(edge[2][\"move\"]), self.get_node_value(graph, edge[1]), graph.nodes(data=True)[edge[1]][\"visits\"]) for edge in list(graph.out_edges(node_list, data=True))]\n",
        "      # print(len(l))\n",
        "      l += [(node, None, 0) for node in node_list]\n",
        "\n",
        "      for data in l:\n",
        "        if data[0] not in self.node_values.keys():\n",
        "\n",
        "          self.node_values[data[0]] = (np.zeros(shape=(19,19)), np.zeros(shape=(19,19)), np.zeros(shape=(19,19)))\n",
        "          \n",
        "          if data[1] is not None:\n",
        "            # Add outcome score for child\n",
        "            self.node_values[data[0]][0][data[1]] = data[2]\n",
        "            # Add 1 to indicate that a node has been visited for masking training later\n",
        "            self.node_values[data[0]][1][data[1]] = 1\n",
        "            # Update visit count for particular child node\n",
        "            self.node_values[data[0]][2][data[1]] = data[3]\n",
        "\n",
        "        else:\n",
        "          if data[1] is not None:\n",
        "            # Add outcome score for child\n",
        "            self.node_values[data[0]][0][data[1]] = data[2]\n",
        "            # Add 1 to indicate that a node has been visited for masking training later\n",
        "            self.node_values[data[0]][1][data[1]] = 1\n",
        "            # Update visit count for particular child node\n",
        "            self.node_values[data[0]][2][data[1]] = data[3]\n",
        "\n",
        "      if not random_agent:\n",
        "\n",
        "        parent_count_array = np.array([graph.nodes(data=True)[node][\"visits\"] if node in graph else 0 for node in node_list]).reshape((n, 1, 1, 1))\n",
        "        child_count_array = np.array([self.node_values[node][2] for node in node_list]).reshape((n, 19, 19, 1))\n",
        "        masks = np.array([self.node_values[node][1] for node in node_list])\n",
        "        outcome_array = np.array([self.node_values[node][0] for node in node_list]).reshape((n, 19, 19, 1))\n",
        "\n",
        "        policy_preds = self.model.predict([boards, inp2])\n",
        "\n",
        "        ucb_score = np.array([outcome_array + self.c * (policy_preds / self.scale_factor) * np.sqrt(np.divide(np.log(parent_count_array + .0001), child_count_array + .000000001))]).reshape((n, 19, 19))\n",
        "\n",
        "        np.nan_to_num(ucb_score, copy=False, nan=10000000, posinf=10000000, neginf=-10000000)\n",
        "        # print(\"FINITE UCB_SCORE COUNT:\", np.sum((ucb_score != 10000000)))\n",
        "        \n",
        "        return ucb_score\n",
        "      \n",
        "      else:\n",
        "\n",
        "        return np.random.uniform(0,1,size=(n, 19, 19))\n",
        "      \n",
        "    else:\n",
        "\n",
        "      if not random_agent:\n",
        "\n",
        "        policy_preds = self.model.predict([boards, inp2])\n",
        "        np.nan_to_num(policy_preds, copy=False, nan=10000000, posinf=10000000, neginf=-10000000)\n",
        "        return policy_preds.reshape(n, 19, 19)\n",
        "\n",
        "      else:\n",
        "\n",
        "        return np.random.uniform(0,1,size=(n, 19, 19))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fGjSXJtz1m-"
      },
      "outputs": [],
      "source": [
        "# REPLACE WITH YOUR PATH FOR SAVING MODELS\n",
        "path = \"models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2_gxD8Lxjd3",
        "outputId": "c81f94b3-ed8c-4241-b999-7c7794754de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 19, 19, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " gaussian_noise_10 (GaussianNoi  (None, 19, 19, 1)   0           ['input_3[0][0]']                \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 17, 17, 128)  1280        ['gaussian_noise_10[0][0]']      \n",
            "                                                                                                  \n",
            " gaussian_noise_11 (GaussianNoi  (None, 17, 17, 128)  0          ['conv2d_5[0][0]']               \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 15, 15, 64)   73792       ['gaussian_noise_11[0][0]']      \n",
            "                                                                                                  \n",
            " gaussian_noise_12 (GaussianNoi  (None, 15, 15, 64)  0           ['conv2d_6[0][0]']               \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 13, 13, 32)   18464       ['gaussian_noise_12[0][0]']      \n",
            "                                                                                                  \n",
            " gaussian_noise_13 (GaussianNoi  (None, 13, 13, 32)  0           ['conv2d_7[0][0]']               \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 11, 11, 16)   4624        ['gaussian_noise_13[0][0]']      \n",
            "                                                                                                  \n",
            " gaussian_noise_14 (GaussianNoi  (None, 11, 11, 16)  0           ['conv2d_8[0][0]']               \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 9, 9, 16)     2320        ['gaussian_noise_14[0][0]']      \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1296)         0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 2, 4)         8           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 398)          516206      ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 8)            0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 406)          0           ['dense_3[0][0]',                \n",
            "                                                                  'flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 256)          104192      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 400)          102800      ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 400)         800         ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 5, 5, 16)     0           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 7, 7, 16)    2320        ['reshape_1[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " gaussian_noise_15 (GaussianNoi  (None, 7, 7, 16)    0           ['conv2d_transpose_7[0][0]']     \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2DTran  (None, 9, 9, 16)    2320        ['gaussian_noise_15[0][0]']      \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " gaussian_noise_16 (GaussianNoi  (None, 9, 9, 16)    0           ['conv2d_transpose_8[0][0]']     \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2DTran  (None, 11, 11, 16)  2320        ['gaussian_noise_16[0][0]']      \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " gaussian_noise_17 (GaussianNoi  (None, 11, 11, 16)  0           ['conv2d_transpose_9[0][0]']     \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2DTra  (None, 13, 13, 32)  4640        ['gaussian_noise_17[0][0]']      \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 13, 13, 32)   0           ['conv2d_transpose_10[0][0]',    \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2DTra  (None, 15, 15, 64)  18496       ['add_1[0][0]']                  \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " gaussian_noise_18 (GaussianNoi  (None, 15, 15, 64)  0           ['conv2d_transpose_11[0][0]']    \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_12 (Conv2DTra  (None, 17, 17, 8)   4616        ['gaussian_noise_18[0][0]']      \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " gaussian_noise_19 (GaussianNoi  (None, 17, 17, 8)   0           ['conv2d_transpose_12[0][0]']    \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_13 (Conv2DTra  (None, 19, 19, 1)   73          ['gaussian_noise_19[0][0]']      \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, 19, 19, 1)    0           ['conv2d_transpose_13[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 859,271\n",
            "Trainable params: 859,271\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "BATCH 0\n",
            "8/8 [==============================] - 1s 48ms/step\n",
            "TAKING TURN 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-56947904ffd0>:250: RuntimeWarning: invalid value encountered in sqrt\n",
            "  ucb_score = np.array([outcome_array + self.c * (policy_preds / self.scale_factor) * np.sqrt(np.divide(np.log(parent_count_array + .0001), child_count_array + .000000001))]).reshape((n, 19, 19))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 47ms/step\n",
            "TAKING TURN 1\n",
            "8/8 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 2\n",
            "8/8 [==============================] - 1s 89ms/step\n",
            "TAKING TURN 3\n",
            "8/8 [==============================] - 1s 109ms/step\n",
            "TAKING TURN 4\n",
            "8/8 [==============================] - 1s 89ms/step\n",
            "TAKING TURN 5\n",
            "8/8 [==============================] - 1s 98ms/step\n",
            "TAKING TURN 6\n",
            "8/8 [==============================] - 1s 123ms/step\n",
            "TAKING TURN 7\n",
            "8/8 [==============================] - 1s 97ms/step\n",
            "TAKING TURN 8\n",
            "8/8 [==============================] - 1s 85ms/step\n",
            "TAKING TURN 9\n",
            "8/8 [==============================] - 1s 73ms/step\n",
            "TAKING TURN 10\n",
            "8/8 [==============================] - 1s 68ms/step\n",
            "TAKING TURN 11\n",
            "8/8 [==============================] - 1s 97ms/step\n",
            "TAKING TURN 12\n",
            "8/8 [==============================] - 0s 54ms/step\n",
            "TAKING TURN 13\n",
            "8/8 [==============================] - 1s 68ms/step\n",
            "TAKING TURN 14\n",
            "8/8 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 15\n",
            "8/8 [==============================] - 1s 56ms/step\n",
            "TAKING TURN 16\n",
            "8/8 [==============================] - 0s 60ms/step\n",
            "TAKING TURN 17\n",
            "8/8 [==============================] - 1s 70ms/step\n",
            "TAKING TURN 18\n",
            "8/8 [==============================] - 1s 72ms/step\n",
            "TAKING TURN 19\n",
            "8/8 [==============================] - 1s 85ms/step\n",
            "TAKING TURN 20\n",
            "8/8 [==============================] - 1s 100ms/step\n",
            "TAKING TURN 21\n",
            "8/8 [==============================] - 1s 63ms/step\n",
            "TAKING TURN 22\n",
            "8/8 [==============================] - 1s 77ms/step\n",
            "TAKING TURN 23\n",
            "8/8 [==============================] - 1s 137ms/step\n",
            "TAKING TURN 24\n",
            "8/8 [==============================] - 1s 118ms/step\n",
            "TAKING TURN 25\n",
            "8/8 [==============================] - 0s 58ms/step\n",
            "TAKING TURN 26\n",
            "8/8 [==============================] - 1s 110ms/step\n",
            "TAKING TURN 27\n",
            "8/8 [==============================] - 0s 60ms/step\n",
            "TAKING TURN 28\n",
            "8/8 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 29\n",
            "8/8 [==============================] - 0s 58ms/step\n",
            "TAKING TURN 30\n",
            "8/8 [==============================] - 0s 58ms/step\n",
            "TAKING TURN 31\n",
            "8/8 [==============================] - 0s 59ms/step\n",
            "TAKING TURN 32\n",
            "8/8 [==============================] - 0s 59ms/step\n",
            "TAKING TURN 33\n",
            "8/8 [==============================] - 1s 104ms/step\n",
            "TAKING TURN 34\n",
            "8/8 [==============================] - 1s 115ms/step\n",
            "TAKING TURN 35\n",
            "8/8 [==============================] - 1s 91ms/step\n",
            "TAKING TURN 36\n",
            "8/8 [==============================] - 1s 71ms/step\n",
            "TAKING TURN 37\n",
            "8/8 [==============================] - 0s 61ms/step\n",
            "TAKING TURN 38\n",
            "8/8 [==============================] - 1s 60ms/step\n",
            "TAKING TURN 39\n",
            "8/8 [==============================] - 1s 76ms/step\n",
            "TAKING TURN 40\n",
            "8/8 [==============================] - 1s 68ms/step\n",
            "TAKING TURN 41\n",
            "8/8 [==============================] - 1s 71ms/step\n",
            "TAKING TURN 42\n",
            "8/8 [==============================] - 1s 83ms/step\n",
            "TAKING TURN 43\n",
            "8/8 [==============================] - 1s 75ms/step\n",
            "TAKING TURN 44\n",
            "8/8 [==============================] - 1s 69ms/step\n",
            "TAKING TURN 45\n",
            "8/8 [==============================] - 1s 61ms/step\n",
            "TAKING TURN 46\n",
            "8/8 [==============================] - 1s 73ms/step\n",
            "TAKING TURN 47\n",
            "8/8 [==============================] - 1s 59ms/step\n",
            "TAKING TURN 48\n",
            "8/8 [==============================] - 1s 66ms/step\n",
            "TAKING TURN 49\n",
            "8/8 [==============================] - 1s 66ms/step\n",
            "TAKING TURN 50\n",
            "8/8 [==============================] - 1s 64ms/step\n",
            "TAKING TURN 51\n",
            "8/8 [==============================] - 0s 62ms/step\n",
            "TAKING TURN 52\n",
            "8/8 [==============================] - 1s 80ms/step\n",
            "TAKING TURN 53\n",
            "8/8 [==============================] - 1s 64ms/step\n",
            "TAKING TURN 54\n",
            "8/8 [==============================] - 1s 64ms/step\n",
            "TAKING TURN 55\n",
            "8/8 [==============================] - 1s 97ms/step\n",
            "TAKING TURN 56\n",
            "8/8 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 57\n",
            "8/8 [==============================] - 0s 61ms/step\n",
            "TAKING TURN 58\n",
            "8/8 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 59\n",
            "8/8 [==============================] - 0s 50ms/step\n",
            "TAKING TURN 60\n",
            "8/8 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 61\n",
            "8/8 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 62\n",
            "8/8 [==============================] - 1s 70ms/step\n",
            "TAKING TURN 63\n",
            "8/8 [==============================] - 0s 50ms/step\n",
            "TAKING TURN 64\n",
            "8/8 [==============================] - 0s 58ms/step\n",
            "TAKING TURN 65\n",
            "8/8 [==============================] - 1s 65ms/step\n",
            "TAKING TURN 66\n",
            "8/8 [==============================] - 1s 85ms/step\n",
            "TAKING TURN 67\n",
            "8/8 [==============================] - 1s 90ms/step\n",
            "TAKING TURN 68\n",
            "8/8 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 69\n",
            "8/8 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 70\n",
            "8/8 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 71\n",
            "8/8 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 72\n",
            "8/8 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 73\n",
            "8/8 [==============================] - 0s 51ms/step\n",
            "TAKING TURN 74\n",
            "8/8 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 75\n",
            "8/8 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 76\n",
            "8/8 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 77\n",
            "8/8 [==============================] - 0s 51ms/step\n",
            "TAKING TURN 78\n",
            "8/8 [==============================] - 0s 52ms/step\n",
            "TAKING TURN 79\n",
            "8/8 [==============================] - 1s 63ms/step\n",
            "TAKING TURN 80\n",
            "8/8 [==============================] - 1s 79ms/step\n",
            "TAKING TURN 81\n",
            "8/8 [==============================] - 0s 50ms/step\n",
            "TAKING TURN 82\n",
            "8/8 [==============================] - 0s 53ms/step\n",
            "TAKING TURN 83\n",
            "8/8 [==============================] - 0s 51ms/step\n",
            "TAKING TURN 84\n",
            "8/8 [==============================] - 0s 59ms/step\n",
            "TAKING TURN 85\n",
            "8/8 [==============================] - 1s 66ms/step\n",
            "TAKING TURN 86\n",
            "8/8 [==============================] - 1s 75ms/step\n",
            "TAKING TURN 87\n",
            "8/8 [==============================] - 1s 68ms/step\n",
            "TAKING TURN 88\n",
            "8/8 [==============================] - 1s 76ms/step\n",
            "TAKING TURN 89\n",
            "8/8 [==============================] - 1s 64ms/step\n",
            "TAKING TURN 90\n",
            "8/8 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 91\n",
            "8/8 [==============================] - 1s 84ms/step\n",
            "TAKING TURN 92\n",
            "8/8 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 93\n",
            "8/8 [==============================] - 0s 47ms/step\n",
            "TAKING TURN 94\n",
            "8/8 [==============================] - 0s 47ms/step\n",
            "TAKING TURN 95\n",
            "8/8 [==============================] - 0s 46ms/step\n",
            "TAKING TURN 96\n",
            "8/8 [==============================] - 0s 46ms/step\n",
            "TAKING TURN 97\n",
            "8/8 [==============================] - 0s 42ms/step\n",
            "TAKING TURN 98\n",
            "8/8 [==============================] - 0s 42ms/step\n",
            "TAKING TURN 99\n",
            "8/8 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 100\n",
            "8/8 [==============================] - 0s 44ms/step\n",
            "TAKING TURN 101\n",
            "8/8 [==============================] - 0s 44ms/step\n",
            "TAKING TURN 102\n",
            "8/8 [==============================] - 1s 104ms/step\n",
            "TAKING TURN 103\n",
            "8/8 [==============================] - 1s 87ms/step\n",
            "TAKING TURN 104\n",
            "8/8 [==============================] - 1s 65ms/step\n",
            "TAKING TURN 105\n",
            "8/8 [==============================] - 1s 63ms/step\n",
            "TAKING TURN 106\n",
            "8/8 [==============================] - 0s 45ms/step\n",
            "TAKING TURN 107\n",
            "8/8 [==============================] - 0s 47ms/step\n",
            "TAKING TURN 108\n",
            "8/8 [==============================] - 1s 76ms/step\n",
            "TAKING TURN 109\n",
            "7/7 [==============================] - 0s 45ms/step\n",
            "TAKING TURN 110\n",
            "7/7 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 111\n",
            "7/7 [==============================] - 0s 50ms/step\n",
            "TAKING TURN 112\n",
            "7/7 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 113\n",
            "7/7 [==============================] - 0s 60ms/step\n",
            "TAKING TURN 114\n",
            "7/7 [==============================] - 1s 78ms/step\n",
            "TAKING TURN 115\n",
            "7/7 [==============================] - 1s 97ms/step\n",
            "TAKING TURN 116\n",
            "7/7 [==============================] - 1s 99ms/step\n",
            "TAKING TURN 117\n",
            "7/7 [==============================] - 1s 99ms/step\n",
            "TAKING TURN 118\n",
            "7/7 [==============================] - 1s 87ms/step\n",
            "TAKING TURN 119\n",
            "7/7 [==============================] - 1s 89ms/step\n",
            "TAKING TURN 120\n",
            "7/7 [==============================] - 1s 112ms/step\n",
            "TAKING TURN 121\n",
            "7/7 [==============================] - 0s 45ms/step\n",
            "TAKING TURN 122\n",
            "7/7 [==============================] - 0s 46ms/step\n",
            "TAKING TURN 123\n",
            "7/7 [==============================] - 0s 44ms/step\n",
            "TAKING TURN 124\n",
            "7/7 [==============================] - 0s 44ms/step\n",
            "TAKING TURN 125\n",
            "7/7 [==============================] - 0s 50ms/step\n",
            "TAKING TURN 126\n",
            "7/7 [==============================] - 1s 81ms/step\n",
            "TAKING TURN 127\n",
            "7/7 [==============================] - 1s 80ms/step\n",
            "TAKING TURN 128\n",
            "7/7 [==============================] - 0s 46ms/step\n",
            "TAKING TURN 129\n",
            "7/7 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 130\n",
            "7/7 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 131\n",
            "6/6 [==============================] - 0s 51ms/step\n",
            "TAKING TURN 132\n",
            "6/6 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 133\n",
            "6/6 [==============================] - 0s 50ms/step\n",
            "TAKING TURN 134\n",
            "6/6 [==============================] - 0s 84ms/step\n",
            "TAKING TURN 135\n",
            "6/6 [==============================] - 0s 77ms/step\n",
            "TAKING TURN 136\n",
            "6/6 [==============================] - 0s 78ms/step\n",
            "TAKING TURN 137\n",
            "6/6 [==============================] - 0s 51ms/step\n",
            "TAKING TURN 138\n",
            "6/6 [==============================] - 0s 63ms/step\n",
            "TAKING TURN 139\n",
            "6/6 [==============================] - 0s 54ms/step\n",
            "TAKING TURN 140\n",
            "6/6 [==============================] - 0s 69ms/step\n",
            "TAKING TURN 141\n",
            "6/6 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 142\n",
            "6/6 [==============================] - 0s 60ms/step\n",
            "TAKING TURN 143\n",
            "6/6 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 144\n",
            "6/6 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 145\n",
            "6/6 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 146\n",
            "5/5 [==============================] - 0s 66ms/step\n",
            "TAKING TURN 147\n",
            "5/5 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 148\n",
            "5/5 [==============================] - 0s 58ms/step\n",
            "TAKING TURN 149\n",
            "5/5 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 150\n",
            "5/5 [==============================] - 0s 52ms/step\n",
            "TAKING TURN 151\n",
            "5/5 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 152\n",
            "5/5 [==============================] - 0s 47ms/step\n",
            "TAKING TURN 153\n",
            "5/5 [==============================] - 1s 103ms/step\n",
            "TAKING TURN 154\n",
            "5/5 [==============================] - 0s 92ms/step\n",
            "TAKING TURN 155\n",
            "5/5 [==============================] - 0s 42ms/step\n",
            "TAKING TURN 156\n",
            "5/5 [==============================] - 0s 78ms/step\n",
            "TAKING TURN 157\n",
            "5/5 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 158\n",
            "5/5 [==============================] - 0s 36ms/step\n",
            "TAKING TURN 159\n",
            "5/5 [==============================] - 0s 40ms/step\n",
            "TAKING TURN 160\n",
            "4/4 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 161\n",
            "4/4 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 162\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "TAKING TURN 163\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "TAKING TURN 164\n",
            "4/4 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 165\n",
            "4/4 [==============================] - 0s 41ms/step\n",
            "TAKING TURN 166\n",
            "4/4 [==============================] - 0s 40ms/step\n",
            "TAKING TURN 167\n",
            "4/4 [==============================] - 0s 39ms/step\n",
            "TAKING TURN 168\n",
            "4/4 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 169\n",
            "4/4 [==============================] - 0s 37ms/step\n",
            "TAKING TURN 170\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "TAKING TURN 171\n",
            "4/4 [==============================] - 0s 35ms/step\n",
            "TAKING TURN 172\n",
            "3/3 [==============================] - 0s 44ms/step\n",
            "TAKING TURN 173\n",
            "3/3 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 174\n",
            "3/3 [==============================] - 0s 40ms/step\n",
            "TAKING TURN 175\n",
            "3/3 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 176\n",
            "3/3 [==============================] - 0s 34ms/step\n",
            "TAKING TURN 177\n",
            "3/3 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 178\n",
            "3/3 [==============================] - 0s 40ms/step\n",
            "TAKING TURN 179\n",
            "3/3 [==============================] - 0s 39ms/step\n",
            "TAKING TURN 180\n",
            "3/3 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 181\n",
            "3/3 [==============================] - 0s 29ms/step\n",
            "TAKING TURN 182\n",
            "3/3 [==============================] - 0s 33ms/step\n",
            "TAKING TURN 183\n",
            "2/2 [==============================] - 0s 45ms/step\n",
            "TAKING TURN 184\n",
            "2/2 [==============================] - 0s 40ms/step\n",
            "TAKING TURN 185\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 186\n",
            "2/2 [==============================] - 0s 32ms/step\n",
            "TAKING TURN 187\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "TAKING TURN 188\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "TAKING TURN 189\n",
            "2/2 [==============================] - 0s 24ms/step\n",
            "TAKING TURN 190\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "TAKING TURN 191\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "TAKING TURN 192\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "TAKING TURN 193\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "TAKING TURN 194\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "TAKING TURN 195\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "TAKING TURN 196\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "TAKING TURN 197\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "TAKING TURN 198\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "TAKING TURN 199\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "TAKING TURN 200\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "TAKING TURN 201\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "TAKING TURN 202\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "TAKING TURN 203\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "TAKING TURN 204\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 205\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 206\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "TAKING TURN 207\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "TAKING TURN 208\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "TAKING TURN 209\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "TAKING TURN 210\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "TAKING TURN 211\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "TAKING TURN 212\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "TAKING TURN 213\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "TAKING TURN 214\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "TAKING TURN 215\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "TAKING TURN 216\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "TAKING TURN 217\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "TAKING TURN 218\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "TAKING TURN 219\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "TAKING TURN 220\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "TAKING TURN 221\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "TAKING TURN 222\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "TAKING TURN 223\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "TAKING TURN 224\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "TAKING TURN 225\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "TAKING TURN 226\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "TAKING TURN 227\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "TAKING TURN 228\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "TAKING TURN 229\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "TAKING TURN 230\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "TAKING TURN 231\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "TAKING TURN 232\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "TAKING TURN 233\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "TAKING TURN 234\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "TAKING TURN 235\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "TAKING TURN 236\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "TAKING TURN 237\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "TAKING TURN 238\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "TAKING TURN 239\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "TAKING TURN 240\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "TAKING TURN 241\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "TAKING TURN 242\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "TAKING TURN 243\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "TAKING TURN 244\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "TAKING TURN 245\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "TAKING TURN 246\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "TAKING TURN 247\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "TAKING TURN 248\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "TAKING TURN 249\n",
            "DONE PLAYING 256 PENTE GAMES\n",
            "==================\n",
            "Player 0 won  53.515625 percent of games\n",
            "Player 1 won  46.484375 percent of games\n",
            "==================\n",
            "===============\n",
            "GRAPH DETAILS\n",
            "DiGraph with 40119 nodes and 40118 edges\n",
            "===============\n",
            "===============\n",
            "BATCH 0\n",
            "===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9935, 19, 19, 1)\n",
            "280/280 [==============================] - 841s 3s/step - loss: 0.2473 - val_loss: 0.2944\n",
            "(9940, 19, 19, 1)\n",
            "280/280 [==============================] - 836s 3s/step - loss: 0.2466 - val_loss: 0.2934\n",
            "(9945, 19, 19, 1)\n",
            " 53/280 [====>.........................] - ETA: 10:46 - loss: 0.2460"
          ]
        }
      ],
      "source": [
        "# max_num = max([int(d.split(\"_\")[-1]) for d in os.listdir(\"models\")])\n",
        "\n",
        "# agent0 = Agent(agent_path=f\"models/pente_ai_{max_num}\")\n",
        "\n",
        "agent0 = Agent()\n",
        "\n",
        "multi = MultiPente(n_games = 1000)\n",
        "\n",
        "num_batches = 10\n",
        "\n",
        "path = \"graph.pkl\"\n",
        "\n",
        "# Start with random playouts to train on\n",
        "# for batch in range(1):\n",
        "#   multi.play_train(agent0, agent0, make_random_moves=[True, True], num_games=5000)\n",
        "\n",
        "# EDIT NUMBER OF BATCHES TO RUN HERE.\n",
        "# EVEN ONE OR TWO WILL TAKE A FAIR BIT OF TIME.\n",
        "num_batches = 500\n",
        "\n",
        "agent_win_rate = []\n",
        "batches = []\n",
        "\n",
        "# Then add \"intelligent\" agent playouts\n",
        "for batch in range(num_batches):\n",
        "\n",
        "  print(\"BATCH\", batch)\n",
        "  multi.play_train(agent0, agent0, num_games=256)\n",
        "\n",
        "  print(\"===============\")\n",
        "  print(\"GRAPH DETAILS\")\n",
        "  print(multi.graph)\n",
        "  print(\"===============\")\n",
        "  print(\"===============\")\n",
        "  print(\"BATCH\", batch)\n",
        "  print(\"===============\")\n",
        "\n",
        "  # zerowinrate, onewinrate = multi.play_test(agent0, agent0, make_random_moves=[True, False], num_games=512)\n",
        "  # agent_win_rate.append(onewinrate)\n",
        "  # batches.append(batch)\n",
        "\n",
        "  if batch % 5 == 0:\n",
        "    keras.models.save_model(agent0.model, f\"{path}/pente_ai_{batch}\")\n",
        "\n",
        "  # plt.scatter(x=batches, y=agent_win_rate)\n",
        "  # plt.savefig(f\"plots/{batch}.png\")\n",
        "\n",
        "  agent0.fit_on_graph(multi.graph, num_epochs=3, batch_size=512, sample_size=10000)\n",
        "\n",
        "  \n",
        "\n",
        "# with open(path, \"wb\") as f:\n",
        "#   pickle.dump(multi.graph, f)\n",
        "\n",
        "# keras.models.save_model(agent0.model, f\"drive/MyDrive/pente_ai.h5\")\n",
        "# agent0.fit_on_graph(multi.graph, num_epochs=1000)\n",
        "# keras.models.save_model(agent0.model, f\"drive/MyDrive/pente_ai.h5\")\n",
        "\n",
        "# nx.draw(multi.graph, node_size=10)\n",
        "\n",
        "# roots = {n for n,d in multi.graph.in_degree() if d==0}\n",
        "\n",
        "# len(roots)\n",
        "\n",
        "\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKLpS0FtzZg7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
